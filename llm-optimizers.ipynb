{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2023-12-01T21:54:22.742181900Z",
     "start_time": "2023-12-01T21:54:20.336163600Z"
    }
   },
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "data": {
      "text/plain": "True"
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "load_dotenv()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-01T21:54:22.763080700Z",
     "start_time": "2023-12-01T21:54:22.745183900Z"
    }
   },
   "id": "1fef47775f20fab3"
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [],
   "source": [
    "def generate_synthetic_data(n_points, w_true, b_true):\n",
    "    points = torch.arange(1, n_points + 1)\n",
    "    y = w_true * points + b_true + torch.randn(n_points)\n",
    "    return [(points[i].item(), y[i].item()) for i in range(n_points)]\n",
    "\n",
    "def sample_starting_region(n_points, starting_region):\n",
    "    w = torch.randint(low=starting_region[0], high=starting_region[1], size=(n_points,))\n",
    "    b = torch.randint(low=starting_region[0], high=starting_region[1], size=(n_points,))\n",
    "    pairs = [(w[i].item(), b[i].item()) for i in range(n_points)]\n",
    "    return pairs\n",
    "\n",
    "init_data = sample_starting_region(n_points=5, starting_region=[10, 20])  "
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-01T21:55:15.786559Z",
     "start_time": "2023-12-01T21:55:15.780163200Z"
    }
   },
   "id": "2f403a2d8715aae0"
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [
    {
     "data": {
      "text/plain": "[(15, 17), (18, 10), (17, 15), (10, 14), (11, 19)]"
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "init_data"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-01T21:55:15.982009400Z",
     "start_time": "2023-12-01T21:55:15.960222400Z"
    }
   },
   "id": "8cb1ee41f4db01f4"
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "\n",
    "class OpenAIWrapper:\n",
    "    def __init__(self, model=\"gpt-3.5-turbo-1106\"):\n",
    "        self.client = OpenAI()\n",
    "        self.model = model\n",
    "        \n",
    "    def __call__(self, system_prompt, user_prompt, temperature):\n",
    "        completion = self.client.chat.completions.create(\n",
    "            model=self.model,\n",
    "            messages=[{\"role\": \"system\", \"content\": system_prompt},\n",
    "                      {\"role\": \"user\", \"content\": user_prompt}],\n",
    "            temperature=temperature,\n",
    "        )\n",
    "        return completion.choices[0].message.content\n",
    "\n",
    "llm = OpenAIWrapper()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-01T21:55:25.413964Z",
     "start_time": "2023-12-01T21:55:25.159429800Z"
    }
   },
   "id": "9429d6c9ceba4d6"
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "class ObjectiveFunction:\n",
    "    def __init__(self, synthetic_data):\n",
    "        self.synthetic_data = synthetic_data\n",
    "        \n",
    "    def __call__(self, w, b):\n",
    "        return int(sum([(y - (w * x + b)) ** 2 for x, y in self.synthetic_data]))\n",
    "\n",
    "def generate_new_solutions(pairs, n=8):\n",
    "    system_prompt = \"You are a helpful assistant\"\n",
    "    user_prompt = f\"Now you will help me minimize a function with two input variables w, b. I have some (w, b) pairs and the function values at those points. The pairs are arranged in descending order based on their function values, where lower values are better.\\n\\n\"\n",
    "    for pair in pairs[::-1]:\n",
    "        w, b, value = pair\n",
    "        user_prompt += f\"Input:\\nw={w}, b={b}\\nValue:\\n{value}\\n\\n\"\n",
    "    user_prompt += f\"Give me a new (w, b) pair that is different from all pairs above, and has a function value lower than all of the above. Do not write code. Do not ask me questions. Please ensure the output contains the new pair in this format: [w, b], where w and b are integer values.\"\n",
    "    solution = [llm(system_prompt, user_prompt, temperature=1) for _ in range(n)]\n",
    "    parsed_solution = [parse_pair(text) for text in solution if parse_pair(text) is not None]\n",
    "    return parsed_solution\n",
    "\n",
    "def parse_pair(text):\n",
    "    # Use regular expression to find numbers in the format [w, b]\n",
    "    match1 = re.search(r'w\\s*=\\s*(-?\\d+\\.?\\d*)\\s*,\\s*b\\s*=\\s*(-?\\d+\\.?\\d*)\\s*', text)\n",
    "    match2 = re.search(r'\\[\\s*(-?\\d+\\.?\\d*)\\s*,\\s*(-?\\d+\\.?\\d*)\\s*\\]', text)\n",
    "    if match1 or match2:\n",
    "        # Extract w and b, convert them to float or int\n",
    "        w, b = match1.groups() if match1 else match2.groups()\n",
    "        w = float(w) if '.' in w else int(w)\n",
    "        b = float(b) if '.' in b else int(b)\n",
    "        return w, b\n",
    "    else:\n",
    "        # print(f\"Could not parse pair from text: {text}\")\n",
    "        return None"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-01T22:31:47.507211200Z",
     "start_time": "2023-12-01T22:31:47.493159200Z"
    }
   },
   "id": "52a93c4e65ccff4"
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "outputs": [],
   "source": [
    "from collections import namedtuple\n",
    "from operator import attrgetter\n",
    "\n",
    "Solution = namedtuple(\"Solution\", \"w b value\")\n",
    "\n",
    "true_data = [(15, 14), (17, 17), (16, 10)]\n",
    "results = {}\n",
    "replicas = 5\n",
    "max_steps = 30 \n",
    "for w_true, b_true in true_data:\n",
    "    steps = []\n",
    "    for _ in range(replicas):\n",
    "        synthetic_data = generate_synthetic_data(n_points=50, w_true=w_true, b_true=b_true)\n",
    "        objective_function = ObjectiveFunction(synthetic_data)\n",
    "        history = [Solution(pair[0], pair[1], objective_function(*pair)) for pair in init_data]\n",
    "        for step in range(1, max_steps + 1):\n",
    "            best_pairs = sorted(history, key=attrgetter(\"value\"))[:20]\n",
    "            new_solutions = generate_new_solutions(best_pairs, n=8)\n",
    "            best_solution = min(new_solutions, key=lambda x: objective_function(*x))\n",
    "            history.append(Solution(best_solution[0], best_solution[1], objective_function(*best_solution)))\n",
    "            if best_solution == (w_true, b_true):\n",
    "                steps.append(step)\n",
    "                break\n",
    "    results[(w_true, b_true)] = steps \n",
    "        "
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-01T22:48:35.851002100Z",
     "start_time": "2023-12-01T22:31:48.336472200Z"
    }
   },
   "id": "938d3ae62d9a0d5c"
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(15, 14): 8.8 +- 4.445222154178574\n",
      "(17, 17): 13.0 +- 4.09878030638384\n",
      "(16, 10): 8.0 +- 4.06201920231798\n"
     ]
    }
   ],
   "source": [
    "# calculate mean and std for each true pair\n",
    "import numpy as np\n",
    "for key, value in results.items():\n",
    "    print(f\"{key}: {np.mean(value)} +- {np.std(value)}\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-01T22:51:52.838567400Z",
     "start_time": "2023-12-01T22:51:52.825559900Z"
    }
   },
   "id": "1dd63000a6160c1e"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "77631e7e34802761"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
